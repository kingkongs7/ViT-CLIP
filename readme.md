# Unveiling the Role of ViT-CLIP in Deepfake Detection: A Systematic Analysis and Novel Module Design

This repository contains the implementation of ViT-CLIP for deepfake detection, a model that leverages the power of Vision Transformer (ViT) and CLIP for robust detection of deepfake images. The goal of this project is to investigate the effectiveness of ViT-CLIP in identifying deepfake images by exploring its internal mechanisms and contributing to its performance enhancement through simple yet efficient module designs.

# Table of Contents
- intorduction
- setup and installation
- usage
- results
- contributing

# Deepfake Detection Based on DeepfakeBench

Our work is based on [DeepfakeBench](https://github.com/SCLBD/DeepfakeBench). The usage follows exactly the same instructions as DeepfakeBench.

## Setup

To get started, simply copy the relevant files from the `training` directory to the corresponding locations as instructed in the DeepfakeBench repository.


Soon we will release our code, weights and data……
